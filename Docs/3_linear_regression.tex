\section{Linear Regression}

\begin{align*}
    h(x) &= w^T \cdot x &\\ 
    L_{\text{MSE}}(y, h(x)) &= (y-h(x))^2 & [\text{Mean Squared Error Loss}]\\
    w_i &= w_i - \alpha \times \frac{\partial}{\partial w_i} L_{\text{MSE}}(y_i, h(x_i)) & [\text{Weight Update}]\\
    &= w_i - \alpha \times x_i(h(x_i) - y_i)\\
    w &= w -\alpha \times \sum^{B}_{i=0} x_i(h(x_i) - y_i)\\
\end{align*}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        node/.style=draw, circle, minimum size=3em,
        forward/.style=->, >=stealth,
        scale=2
    ]
        \node[node] (x) at (0, 0) {$x$};
        \node[node] (hx) at (1, 0) {$h(x)$};
        \draw[forward] (x) edge node [midway, above] {$w$} (z);
        \node[node] (y) at (1, -1) {$y$};
        \node[node] (l) at (2, -0) {$L$};
        \draw[forward] (hx) -- (l);
        \draw[forward] (y) -- (l);
    \end{tikzpicture}
    \caption{Linear Regression Computation Graph}
\end{figure}

\subsection{Derivations}
Derivative of Mean Squared Error with respect to weight $w_i$\\

\begin{align*}
    \frac{\partial}{\partial w_i} L_{\text{MSE}}(y_i, h(x_i)) &= \frac{\partial}{\partial w_i} (y_i - h(x_i))^2\\
    &= 2(y_i - h(x_i)) \times \frac{\partial}{\partial w_i} (y_i - h(x_i))\\
    &= 2(y_i - h(x_i)) \times \left(\frac{\partial}{\partial w_i} y_i - \frac{\partial}{\partial w_i}h(x_i)\right)\\
    &= 2(y_i - h(x_i)) \times \left(-\frac{\partial}{\partial w_i}w_i \times x_i\right)\\
    &= -2x_i(y_i - h(x_i))\\
    &= 2x_i(h(x_i)-y_i)\\
    &\propto x_i(h(x_i)-y_i)\\
\end{align*}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dying-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-binding",
   "metadata": {},
   "source": [
    "---\n",
    "slug: \"/blog/wordembeddings\"\n",
    "date: \"2021-05-13\"\n",
    "title: \"Word Embeddings\"\n",
    "category: \"3 Natural Language Processing\"\n",
    "order: 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-amazon",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Word embeddings are a method of representation learning that seeks to turn words into vectors such that when a pair of vectors $\\vec{w}_1$ and $\\vec{w}_2$ are close to each other, the words that they represent are semantically similar, and when the vectors are far away, the corresponding words are semantically distant from each other. \n",
    "Generally speaking, word embeddings are constructed by leveraging the distributional semantics hypothesis, which states that words that appear in similar contexts, or have similar distributions, are semantically similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-replica",
   "metadata": {},
   "source": [
    "### Co-occurrence Vectors\n",
    "\n",
    "Creating co-occurrence vectors for words in a corpus a simple way of representing words as vectors in a space that models semantic relationships between words.\n",
    "One way to create co-occurrence vectors is to create $V$ vectors of size $V$, where $V$ is the total size of the vocabulary. \n",
    "When two words, $w_1$ and $w_2$ are in the same document, the $w_2$ column for $w_1$ is incremented by 1, and the $w_1$ column for $w_2$ is incremented by 1. \n",
    "In another approach, increments can be made when two words are within a preset window size of each other.\n",
    "\n",
    "In the example corpus shown below, there only four documents, and only the words immediately previous and immediately following a given word $w$ are considered when creating its co-occurrence embedding.\n",
    "There are a total of 7 words in the entire vocabulary, so there are 7 co-occurrence vectors (shown below), each of size 7.\n",
    "The row representing \"likes\" contains a 1 in the \"Bob\" column because the \"Bob\" appears next to \"likes\" in at least one document in the corpus.\n",
    "Similarly, the \"likes\" row also contains a 1 in the \"pizza\" and \"wings\" columns\n",
    "\n",
    "1. Bob likes pizza\n",
    "2. Bob likes wings\n",
    "3. Bob dislikes kale\n",
    "3. Bob dislikes lettuce\n",
    "\n",
    "| |Bob|dislikes|kale|lettuce|likes|pizza|wings|\n",
    "|-|---|--------|----|-------|-----|-----|-----|\n",
    "|Bob|1|1|0|0|1|0|0|\n",
    "|dislikes|1|1|1|1|0|0|0|\n",
    "|kale|0|1|1|0|0|0|0|\n",
    "|lettuce|0|1|0|1|0|0|0|\n",
    "|likes|1|0|0|0|1|1|1|\n",
    "|pizza|0|0|0|0|1|1|0|\n",
    "|wings|0|0|0|0|1|0|1|\n",
    "\n",
    "Despite how simple this corpus and set of word embeddings is, there are still semantic relationships that can be learned.\n",
    "A simple and effective way to check similarity between words using embeddings is cosine similarity, which measures the cosine of the angle between the two embeddings, as shown below.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    csim(w_1, w_2) \n",
    "    &= \n",
    "    \\frac{\n",
    "        w_1 \\cdot w_2\n",
    "    }{\n",
    "        ||w_1|| \\times||w_2||\n",
    "    }\n",
    "    &\n",
    "    [\\text{Cosine Similarity}]\\\\\n",
    "    &=\n",
    "    \\frac{\n",
    "        \\sum_{i=1} {w_1}_i \\times {w_2}_i\n",
    "    }{\n",
    "        \\sqrt{\\sum_{i=1} {{w_1}_i}^2} \\times \\sqrt{\\sum_{i=1} {{w_2}_i}^2}\n",
    "    }\n",
    "    \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Given the example word embedding space defined above, \"lettuce\" and \"kale\" have a cosine similarity of 0.5, and \"pizza\" and \"wings\" have a cosine similarity of 0.5.\n",
    "However the pair \"lettuce\" and \"wings\", or pair \"pizza\" and \"kale\", both have cosine similarities of 0.\n",
    "This is because \"lettuce\" and \"kale\" both appear in context with \"likes\", and \"pizza\" and wings\" both appear in context with \"dislikes\".\n",
    "Measuring semantic similarity using this approach is one way that word embeddings can be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-eight",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-appearance",
   "metadata": {},
   "source": [
    "Using co-occurrence vectors can be effective, but has several limitations.\n",
    "The most obvious limitation is the size of the embeddings ($V$). \n",
    "In addition, in most cases, the entries of vectors will be zero. \n",
    "Word2Vec, an approach developed by Mikolov et al. in 2013 creates dense arbitrarily-sized word embeddings that generally work better than the sparsely populated co-occurrence vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-machinery",
   "metadata": {},
   "source": [
    "At a high level, the word2vec approach learns a binary classifier that determines whether or not a pair of words might appear in the same context or not. \n",
    "In the skip-gram negative sampling approach, a context is a window or sequence of words, and the classifier outputs the probability $p(+|w, c)$, which is the probability that word $c$ might appear in the same context as word $w$.\n",
    "Conversely, $p(-|w, c)$ is the probability that the word $c$ might not appear in the same context as word $w$.\n",
    "The calculations for both of these probabilities are shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-science",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "    \\sigma(x) &= \\frac{1}{1 + e^{-x}} & [\\text{Sigmoid function}]\\\\\n",
    "    p(+|w, c) &= \\sigma(c \\cdot w) & [\\text{Probability c is context word}]\\\\\n",
    "    p(-|w, c) &= 1 - p(+|w, c) = \\sigma(-c \\cdot w) & [\\text{Probability c is not context word}]\\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-upgrade",
   "metadata": {},
   "source": [
    "The loss function for the word2vec model maximizes the probability $p(+|w,c)$ when words $w$ and $c$ do appear in the same window in a training data set.\n",
    "It simultaneously minimizes $p(+|w,c)$ when $c$ is randomly generated, and does not necessarily appear in the same documents as $w$.\n",
    "The loss function and a computation graph for learning word2vec embeddings are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-chapel",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "    L \n",
    "    &= \n",
    "    -\\log\\left[ p(+|w, c_{\\text{pos}})\\prod^K_{i=1} p(-|w, c_{\\text{neg}_i}) \\right] \n",
    "    & \n",
    "    [\\text{Loss function}]\n",
    "    \\\\\n",
    "    &=\n",
    "    -\\left[ \\log p(+|w, c_{\\text{pos}}) + \\sum^K_{i=1} \\log p(-|w, c_{\\text{neg}_i}) \\right] \n",
    "    &\n",
    "    \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fossil-participant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%tikz -s=610,480 -sc=3\n",
    "\\node[draw, circle, minimum width=6em] (w) at (0, 3) {$w$};\n",
    "\\node[draw, circle, minimum width=6em] (cp) at (0, 2) {$c_p$};\n",
    "\\node[draw, circle, minimum width=6em] (cn1) at (0, 1) {${c_n}_1$};\n",
    "\\node[draw, circle, minimum width=6em] (cnk) at (0, 0) {${c_n}_k$};\n",
    "\\node[draw, circle, minimum width=6em] (pcp) at (2, 2) {$p(+|w, c_p)$};\n",
    "\\node[draw, circle, minimum width=6em] (pcn1) at (2, 1) {$p(-|w, {c_n}_1)$};\n",
    "\\node[draw, circle, minimum width=6em] (pcnk) at (2, 0) {$p(-|w, {c_n}_k)$};\n",
    "\\node[draw, circle, minimum width=6em] (l) at (4, 1) {$L$};\n",
    "\\draw[->] (w) -- (pcp);\n",
    "\\draw[->] (w) -- (pcn1);\n",
    "\\draw[->] (w) -- (pcnk);\n",
    "\\draw[->] (cp) -- (pcp);\n",
    "\\draw[->] (cn1) -- (pcn1);\n",
    "\\draw[->] (cnk) -- (pcnk);\n",
    "\\draw[->] (pcp) -- (l);\n",
    "\\draw[->] (pcn1) -- (l);\n",
    "\\draw[->] (pcnk) -- (l);\n",
    "\\draw[dotted, line width=1pt] (cn1) -- (cnk);\n",
    "\\draw[dotted, line width=1pt] (pcn1) -- (pcnk);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-tablet",
   "metadata": {},
   "source": [
    "Given a word $w$ in a document, positive context words are drawn directly from the training data by sampling words that appear within the same window as $w$. \n",
    "Assuming a window size of 2 and the example sentence \"This is an example sentence\", positive context words for \"example\" would be \"an\" and \"sentence\".\n",
    "\n",
    "Negative context words are drawn using a random weighting scheme based on unigram word probabilities.\n",
    "In practice, better performance is achieved by using multiple negative context words for each positive context word for a given word $w$, which is why there are $K$ negative contexts in the loss function.\n",
    "$K$, or the number of negative contexts to use for each postive context of a word $w$, is a word2vec model hyperparameter.\n",
    "The negative sampling probability calculation used in the skip-gram negative sampling approach is displayed below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-centre",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "    c(w) &\\rightarrow \\text{ Count of word $w$} &\\\\\n",
    "    p_{\\alpha}(w) &= \\frac{c(w)^{\\alpha}}{\\sum_{w_i \\in W} c(w_i)^{\\alpha}} & [\\text{Negative sampling probability}]\\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-senior",
   "metadata": {},
   "source": [
    "The required gradients and paremeter update equations for learning using stochastic gradient descent are shown below. \n",
    "Derivations for each of the displayed gradient calculations can be found in the derivations section of this post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-greece",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "    \\frac{\\partial L_{\\text{CE}}}{\\partial w}\n",
    "    &=\n",
    "    c_{\\text{pos}} \\left[\\sigma(c_{\\text{pos}} \\cdot w) - 1\\right] +\n",
    "    \\sum^K_{i=1} c_{\\text{neg}_i} \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    &\n",
    "    [\\text{Gradient wrt $w$}]\n",
    "    \\\\\n",
    "    \\frac{\\partial L_{\\text{CE}}}{\\partial c_{\\text{pos}}}\n",
    "    &=\n",
    "    w [\\sigma(c_{\\text{pos}} \\cdot w) - 1]\n",
    "    &\n",
    "    [\\text{Gradient wrt $c_{\\text{pos}}$}]\n",
    "    \\\\\n",
    "    \\frac{\\partial L_{\\text{CE}}}{\\partial c_{\\text{neg}_i}}\n",
    "    &=\n",
    "    w \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    &\n",
    "    [\\text{Gradient wrt $c_{\\text{neg}_i}$}]\n",
    "    \\\\\n",
    "    w \n",
    "    &= \n",
    "    w - \\alpha \\frac{\\partial L_{\\text{CE}}}{\\partial w}\n",
    "    &\n",
    "    [\\text{$w$ update}]\n",
    "    \\\\\n",
    "    c_{\\text{pos}} \n",
    "    &= \n",
    "    c_{\\text{pos}} - \\alpha \\frac{\\partial L_{\\text{CE}}}{\\partial c_{\\text{pos}}}\n",
    "    &\n",
    "    [\\text{$c_{\\text{pos}}$ update}]\n",
    "    \\\\\n",
    "    c_{\\text{neg}_i} \n",
    "    &= \n",
    "    c_{\\text{neg}_i} - \\alpha \\frac{\\partial L_{\\text{CE}}}{\\partial c_{\\text{neg}_i}}\n",
    "    &\n",
    "    [\\text{$c_{\\text{neg}_i}$ update}]\n",
    "    \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-christmas",
   "metadata": {},
   "source": [
    "### Code\n",
    "\n",
    "Code for a word2vec embedding generator is shown in the block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "respective-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import random\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def getUnigramProbs(dataset: List[str], alpha: float=0.75) -> (List[str], List[float]):\n",
    "    \"\"\" Calculate unigram probabilities for all words in dataset. Probabilities\n",
    "        are weighted to increase the probability of the rarest words\n",
    "\n",
    "    Args:\n",
    "        dataset: list of strings\n",
    "        alpha: weighting hypterparameter\n",
    "\n",
    "    Returns:\n",
    "        list of vocabulary terms sorted by highest to lowest probability\n",
    "        list of probabilities corresponding to the list of vocabulary terms\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect unigram counts\n",
    "    probs = {}\n",
    "    for doc in tqdm(dataset, desc='Calculating Unigram Probabilities'):\n",
    "        words = doc.strip().split(' ')\n",
    "\n",
    "        for word in words: \n",
    "            probs[word] = probs[word] + 1 if word in probs else 1\n",
    "\n",
    "    # Transform counts into probabilities\n",
    "    total = 0\n",
    "    for word in probs: total += probs[word]**alpha\n",
    "    for word in probs: probs[word] = (probs[word]**alpha) / total\n",
    "\n",
    "    # Sort vocabulary by probabilities\n",
    "    probs = sorted(probs.items(), key=lambda x: x[1])[::-1]\n",
    "    vocab, probs = [pair[0] for pair in probs], [pair[1] for pair in probs]\n",
    "\n",
    "    return vocab, probs\n",
    "\n",
    "\n",
    "def csim(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\" Calculate cosine similarity between two vectors\n",
    "    \"\"\"\n",
    "\n",
    "    num = np.dot(x, y.T)\n",
    "    den = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "    return num / den\n",
    "\n",
    "\n",
    "class WeightedSampler:\n",
    "    \"\"\" Implementation of Walker's Alias method for weighted random sampling\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, vocab: List[str], probs: List[float]):\n",
    "        \"\"\" Initialize weighted sampler class\n",
    "\n",
    "        Args:\n",
    "            vocab: list of vocabulary words\n",
    "            probs: list of unigram probabilities for each word\n",
    "        \"\"\"\n",
    "\n",
    "        self.buckets = self.getRandomSamplingBuckets(vocab, probs, 1/len(vocab))\n",
    "        self.tprob = 1 / len(vocab)\n",
    "\n",
    "\n",
    "    def initializeBuckets(self, buckets: List[dict], tprob: float) -> (List[dict], List[dict], List[dict]):\n",
    "        \"\"\" Initialize list of buckets into one of overfull, underfull and full\n",
    "            categories. Buckets are dictionaries containing two vocabulary words\n",
    "            'w1' and 'w2', as well as a splitting probability 's', and a sum of\n",
    "            probabilities 't'\n",
    "\n",
    "        Args:\n",
    "            buckets: list of buckets\n",
    "            tprob: the total probability that each bucket must represent\n",
    "\n",
    "        Returns:\n",
    "            list of buckets that are full\n",
    "            list of buckets that are underfull\n",
    "            list of buckets that are overfull\n",
    "        \"\"\"\n",
    "\n",
    "        full, underfull, overfull = [], [], []\n",
    "\n",
    "        while buckets:\n",
    "            cur = buckets.pop()\n",
    "            if cur['t'] == tprob:\n",
    "                full.append(cur)\n",
    "\n",
    "            elif cur['t'] < tprob:\n",
    "                underfull.append(cur)\n",
    "\n",
    "            else:\n",
    "                overfull.append(cur)\n",
    "\n",
    "        return full, underfull, overfull\n",
    "\n",
    "\n",
    "    def getRandomSamplingBuckets(self, vocab: List[str], probs: List[float], tprob: float) -> List[dict]:\n",
    "        \"\"\" Reorganize buckets until each bucket contains two vocabulary words\n",
    "            and all buckets have an equivalent total probability. Buckets are\n",
    "            dictionaries containing two vocabulary words 'w1' and 'w2', as well\n",
    "            as a splitting probability 's', and a sum of probabilities 't'\n",
    "\n",
    "        Args:\n",
    "            vocab: list of vocabulary words\n",
    "            probs: list of unigram probabilities for each word\n",
    "            tprob: the total probability that each bucket must represent\n",
    "\n",
    "        Returns:\n",
    "            list of buckets s.t. all buckets have two words and the same total probability\n",
    "        \"\"\"\n",
    "\n",
    "        buckets = [ {'w1': vocab[idx], 'w2': None, 's': probs[idx], 't': probs[idx] } for idx in range(len(vocab)) ]\n",
    "        full, underfull, overfull = self.initializeBuckets(buckets, tprob)\n",
    "\n",
    "        while underfull:\n",
    "            under = underfull.pop()\n",
    "            over = overfull.pop()\n",
    "\n",
    "            under['w2'] = over['w1']\n",
    "            under['t'] = tprob \n",
    "            full.append(under)\n",
    "\n",
    "            over['t'] = over['t'] - (tprob - under['s'])\n",
    "            over['s'] = over['s'] - (tprob - under['s'])\n",
    "\n",
    "            if over['t'] == tprob: \n",
    "                full.append(over)\n",
    "\n",
    "            elif over['t'] < tprob: \n",
    "                underfull.append(over)                \n",
    "\n",
    "            else: \n",
    "                overfull.append(over)\n",
    "\n",
    "        full += overfull\n",
    "        return full\n",
    "\n",
    "\n",
    "    def generateWord(self) -> str:\n",
    "        \"\"\" Generate randomly sampled word \n",
    "\n",
    "        Returns:\n",
    "            randomly sampled word as string  \n",
    "        \"\"\"\n",
    "\n",
    "        bucket = random.choice(self.buckets)\n",
    "        splitval = random.uniform(0, self.tprob)\n",
    "\n",
    "        word = None\n",
    "        if splitval >= bucket['s']:\n",
    "            word = bucket['w2']                \n",
    "\n",
    "        else:\n",
    "            word = bucket['w1']                \n",
    "\n",
    "        return word\n",
    "\n",
    "\n",
    "class Windows:\n",
    "    \"\"\" Iterator for sequence of windows on list\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, items: List, wsize: int) -> None:\n",
    "        \"\"\" Instantiate Windows class\n",
    "\n",
    "        Args:\n",
    "            items: list to create windows form\n",
    "            wsize: total number of items to account for on either side of item\n",
    "                Given the list ['this', 'is', 'a', 'test'] with a wsize of 1 the\n",
    "                Windows class will return the following windows in a for loop:\n",
    "                    ['this', 'is']\n",
    "                    ['this', 'is', 'a']\n",
    "                    ['is', 'a', 'test']\n",
    "                    ['a', 'test']\n",
    "        \"\"\"\n",
    "        self.start = -((wsize+1)//2)\n",
    "        self.end = ((wsize+1)//2)+1\n",
    "        self.items = items \n",
    "        self.cidx = 0\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\" Returns iterator\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "\n",
    "    def __next__(self) -> List:\n",
    "        \"\"\" Return next available window of list\n",
    "\n",
    "        Returns:\n",
    "            window of items as a list\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cidx < len(self.items):\n",
    "\n",
    "            if self.end > len(self.items):\n",
    "                seq = self.items[self.start:]\n",
    "\n",
    "            elif self.start < 0:\n",
    "                seq = self.items[:self.end]\n",
    "\n",
    "            else:\n",
    "                seq = self.items[self.start:self.end]\n",
    "\n",
    "            self.start += 1\n",
    "            self.cidx += 1\n",
    "            self.end += 1\n",
    "            return seq\n",
    "\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n",
    "class Word2Vec:\n",
    "    \"\"\" Implementation of Word2Vec word embeddings using skip-gram negative\n",
    "        sampling\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, vocab: List[str], probs: List[float], d: int):\n",
    "        \"\"\" Instantiate word2vec class\n",
    "\n",
    "        Args:\n",
    "            vocab: list of vocabulary words\n",
    "            probs: unigram probabilities of each vocabulary word\n",
    "            d: size of embeddings\n",
    "        \"\"\"\n",
    "\n",
    "        self.w = (np.random.rand(len(vocab), d) - 0.5) / 100\n",
    "        self.c = (np.random.rand(len(vocab), d) - 0.5) / 100\n",
    "        self.sampler = WeightedSampler(vocab, probs)\n",
    "        self.vocab = vocab\n",
    "        self.vdict = { vocab[idx]: idx for idx in range(len(vocab)) }\n",
    "\n",
    "    \n",
    "    def parse(self, document: str) -> List[str]:\n",
    "        \"\"\" Split document into tokens on white spaces\n",
    "\n",
    "        Args:\n",
    "            document: string to parse\n",
    "\n",
    "        Returns:\n",
    "            list of parsed tokens \n",
    "        \"\"\"\n",
    "        return [self.vdict[word] for word in document.strip().split(' ')]\n",
    "\n",
    "\n",
    "    def train(self, corpus: List[str], epochs: int, wsize: int, k: int, alpha: float) -> None:\n",
    "        \"\"\" Train word2vec model\n",
    "\n",
    "        Args:\n",
    "            corpus: list of document strings to train on\n",
    "            epochs: number of passes to take over training corpus\n",
    "            wsize: size of window to examine for skip-grams\n",
    "            k: number of negative samples to consider for each positive sample\n",
    "            alpha: learning rate\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(epochs):\n",
    "            for document in tqdm(corpus, desc='Training Word2Vec Model'):\n",
    "                words = self.parse(document)\n",
    "\n",
    "                cidx = 0\n",
    "                for seq in Windows(words, wsize):\n",
    "                    cpi = seq[:cidx] + seq[cidx+1:]\n",
    "                    wi = [words[cidx]]\n",
    "\n",
    "                    for pi in cpi:\n",
    "                        cni = [self.vdict[self.sampler.generateWord()] for i in range(k)]\n",
    "                        self.weightUpdate(wi, pi, cni, alpha)\n",
    "\n",
    "                    cidx += 1\n",
    "\n",
    "\n",
    "    def weightUpdate(self, wi: List[int], pi: List[int], cni: List[int], alpha: float) -> None:\n",
    "        \"\"\" Update word2vec weights\n",
    "\n",
    "        Args:\n",
    "            wi: list of index for word being trained on\n",
    "            pi: list of index for positive examples\n",
    "            cni: list of indices for negative examples\n",
    "            alpha: learning rate\n",
    "        \"\"\"\n",
    "\n",
    "        # Dot products of positive examples and word and negative examples and word\n",
    "        cpw = np.einsum('ij,kj->i', self.c[[pi], :], self.w[wi, :])\n",
    "        cnw = np.einsum('ij,kj->i', self.c[cni, :], self.w[wi, :])\n",
    "\n",
    "        # Sigmoid function run on dot products\n",
    "        scpw = (1 / (1 + np.exp(-cpw))) - 1\n",
    "        scnw = (1 / (1 + np.exp(-cnw)))[:, None]\n",
    "\n",
    "        # Gradient for matrix w\n",
    "        dwa = self.c[[pi], :] * scpw\n",
    "        dwb = np.sum(self.c[cni, :] * scnw, axis=0)[None, :]\n",
    "        dw = dwa + dwb\n",
    "\n",
    "        # Gradients for matrix c\n",
    "        dcp = self.w[wi, :] * scpw\n",
    "        dcn = self.w[wi, :] * scnw\n",
    "\n",
    "        # Weight updates using calculated gradients\n",
    "        self.w[wi, :] = self.w[wi, :] - (alpha * dw)\n",
    "        self.c[[pi], :] = self.c[[pi], :] - (alpha * dcp)\n",
    "        self.c[cni, :] = self.c[cni, :] - (alpha * dcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-juice",
   "metadata": {},
   "source": [
    "### Derivations\n",
    "\n",
    "Derivative of loss with respect to $w$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\frac{\\partial L_{\\text{CE}}}{\\partial w}\n",
    "    &=\n",
    "    -\\left[\n",
    "        \\log p(+|w, c_{\\text{pos}}) +\n",
    "        \\sum^K_{i=1} \\log p(-|w, c_{\\text{neg}_i})\n",
    "    \\right]\n",
    "    &\n",
    "    \\color{red}{\\text{EQ 1}}\n",
    "    \\\\\n",
    "    &=\n",
    "    -\\frac{\\partial}{\\partial w}\n",
    "    \\left[\n",
    "        \\log p(+|w, c_{\\text{pos}}) +\n",
    "        \\sum^K_{i=1} \\log \\left[1 - p(+|w, c_{\\text{neg}_i})\\right]\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    -\n",
    "    \\left[\n",
    "        \\frac{\\partial}{\\partial w} \\log p(+|w, c_{\\text{pos}}) +\n",
    "        \\sum^K_{i=1} \\frac{\\partial}{\\partial w} \\log \\left[1 - p(+|w, c_{\\text{neg}_i})\\right]\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    -\n",
    "    \\left[\n",
    "        [\\color{red}{\\text{EQ 2}}] +\n",
    "        \\sum^K_{i=1} [\\color{red}{\\text{EQ 3}}]\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    -\n",
    "    \\left[\n",
    "        c_{\\text{pos}} \\left[1 - \\sigma(c_{\\text{pos}} \\cdot w)\\right] +\n",
    "        \\sum^K_{i=1} -c_{\\text{neg}_i} \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    c_{\\text{pos}} \\left[\\sigma(c_{\\text{pos}} \\cdot w) - 1\\right] +\n",
    "    \\sum^K_{i=1} c_{\\text{neg}_i} \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    \\\\\n",
    "    \\frac{\\partial}{\\partial w} \\log p(+|w, c_{\\text{pos}})\n",
    "    &=\n",
    "    \\frac{\\partial}{\\partial w} \\log \\sigma(c_{\\text{pos}} \\cdot w)\n",
    "    &\n",
    "    \\color{red}{\\text{EQ 2}}\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{1}{\\sigma(c_{\\text{pos}} \\cdot w)}\n",
    "    \\frac{\\partial}{\\partial w} \\sigma(c_{\\text{pos}} \\cdot w)\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{1}{\\sigma(c_{\\text{pos}} \\cdot w)}\n",
    "    [\\color{red}{\\text{EQ 4}}]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{1}{\\sigma(c_{\\text{pos}} \\cdot w)}\n",
    "    \\left[\n",
    "        c_{\\text{pos}}\n",
    "        \\sigma(c_{\\text{pos}} \\cdot w)\n",
    "        \\left[1 - \\sigma(c_{\\text{pos}} \\cdot w)\\right]\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{\n",
    "        c_{\\text{pos}}\n",
    "        \\sigma(c_{\\text{pos}} \\cdot w)\n",
    "        \\left[1 - \\sigma(c_{\\text{pos}} \\cdot w)\\right]\n",
    "    }{\\sigma(c_{\\text{pos}} \\cdot w)}\n",
    "    \\\\\n",
    "    &=\n",
    "    c_{\\text{pos}} \\left[1 - \\sigma(c_{\\text{pos}} \\cdot w)\\right]\n",
    "    \\\\\n",
    "    \\frac{\\partial}{\\partial w} \\log \\left[1 - p(+|w, c_{\\text{neg}_i})\\right]\n",
    "    &=\n",
    "    \\frac{\\partial}{\\partial w} \\log \\left[1 - \\sigma(c_{\\text{neg}_i} \\cdot w)\\right]\n",
    "    &\n",
    "    \\color{red}{\\text{EQ 3}}\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{1}{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "    \\frac{\\partial}{\\partial w} \\left[1 - \\sigma(c_{\\text{neg}_i} \\cdot w)\\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{1}{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "    \\frac{\\partial}{\\partial w} \\left[-\\sigma(c_{\\text{neg}_i} \\cdot w)\\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-1}{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "    \\frac{\\partial}{\\partial w} \\left[\\sigma(c_{\\text{neg}_i} \\cdot w)\\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-1}{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "    [\\color{red}{\\text{EQ 4}}]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-1}{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "    \\left[\n",
    "        c_{\\text{neg}_i}\n",
    "        \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "        [1 - \\sigma(c_{\\text{neg}_i} \\cdot w)]\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{\n",
    "        -c_{\\text{neg}_i}\n",
    "        \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    [1 - \\sigma(c_{\\text{neg}_i} \\cdot w)]\n",
    "    }{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "    \\\\\n",
    "    &=\n",
    "    -c_{\\text{neg}_i} \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    \\\\\n",
    "    \\frac{\\partial}{\\partial w} \\sigma(c \\cdot w)\n",
    "    &=\n",
    "    \\frac{\\partial}{\\partial w} \n",
    "    \\frac{1}{1 + e^{-c \\cdot w}}\n",
    "    &\n",
    "    \\color{red}{\\text{EQ 4}}\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{\\partial}{\\partial w} \n",
    "    [1 + e^{-c \\cdot w}]^{-1}\n",
    "    \\\\\n",
    "    &=\n",
    "    -[1 + e^{-c \\cdot w}]^{-2}\n",
    "    \\frac{\\partial}{\\partial w} \n",
    "    [1 + e^{-c \\cdot w}]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-1}{[1 + e^{-c \\cdot w}]^{2}}\n",
    "    \\frac{\\partial}{\\partial w} \n",
    "    [1 + e^{-c \\cdot w}]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-1}{[1 + e^{-c \\cdot w}]^{2}}\n",
    "    \\frac{\\partial}{\\partial w} \n",
    "    e^{-c \\cdot w}\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-e^{-c \\cdot w}}{[1 + e^{-c \\cdot w}]^{2}}\n",
    "    \\frac{\\partial}{\\partial w} \n",
    "    [-c \\cdot w]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{c e^{-c \\cdot w}}{[1 + e^{-c \\cdot w}]^{2}}\n",
    "    \\\\\n",
    "    &=\n",
    "    c\n",
    "    \\left[\\frac{1}{1 + e^{-c \\cdot w}}\\right]\n",
    "    \\left[\\frac{e^{-c \\cdot w}}{1 + e^{-c \\cdot w}}\\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    c\n",
    "    \\sigma(c \\cdot w)\n",
    "    \\left[\\frac{e^{-c \\cdot w}}{1 + e^{-c \\cdot w}}\\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    c\n",
    "    \\sigma(c \\cdot w)\n",
    "    \\left[ \\frac{1 + e^{-c \\cdot w} - 1}{1 + e^{-c \\cdot w}} \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    c\n",
    "    \\sigma(c \\cdot w)\n",
    "    \\left[ \n",
    "        \\frac{1 + e^{-c \\cdot w}}{1 + e^{-c \\cdot w}} -\n",
    "        \\frac{1}{1 + e^{-c \\cdot w}} \n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    c\n",
    "    \\sigma(c \\cdot w)\n",
    "    \\left[1 - \\sigma(c \\cdot w)\\right]\n",
    "    \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Derivative of loss with respect to $c_{\\text{pos}}$ \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\frac{\\partial L_{\\text{CE}}}{\\partial c_{\\text{pos}}}\n",
    "    &=\n",
    "    -\\frac{\\partial}{\\partial c_{\\text{pos}}}\n",
    "    \\left[\n",
    "        \\log p(+|w, c_{\\text{pos}}) + \n",
    "        \\sum^K_{i=1} \\log p(-|w, c_{\\text{neg}_i})\n",
    "    \\right]\n",
    "    &\n",
    "    \\color{red}{\\text{EQ 1}}\n",
    "    \\\\\n",
    "    &= \n",
    "    -\\left[\n",
    "        \\frac{\\partial}{\\partial c_{\\text{pos}}} \\log p(+|w, c_{\\text{pos}}) + \n",
    "        \\sum^K_{i=1} \\frac{\\partial}{\\partial c_{\\text{pos}}} \\log p(-|w, c_{\\text{neg}_i})\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &= \n",
    "    -\\left[\n",
    "        \\frac{\\partial}{\\partial c_{\\text{pos}}} \\log p(+|w, c_{\\text{pos}})\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &= \n",
    "    -\\left[\n",
    "        \\frac{\\partial}{\\partial c_{\\text{pos}}} \\log \\sigma(c_{\\text{pos}} \\cdot w)\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &= \n",
    "    -\\left[\n",
    "        \\frac{1}{\\sigma(c_{\\text{pos}} \\cdot w)}\n",
    "        \\frac{\\partial}{\\partial c_{\\text{pos}}} \\sigma(c_{\\text{pos}} \\cdot w)\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &= \n",
    "    -\\left[\n",
    "        \\frac{1}{\\sigma(c_{\\text{pos}} \\cdot w)}\n",
    "        [\\color{red}{\\text{EQ 2}}]\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &= \n",
    "    -\\left[\n",
    "        \\frac{1}{\\sigma(c_{\\text{pos}} \\cdot w)}\n",
    "        [w \\sigma(c_{\\text{pos}} \\cdot w) \\left[ 1 - \\sigma(c_{\\text{pos}} \\cdot w) \\right]]\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &= \n",
    "    -\\left[\n",
    "        \\frac{\n",
    "            w \\sigma(c_{\\text{pos}} \\cdot w) \\left[ 1 - \\sigma(c_{\\text{pos}} \\cdot w) \\right]\n",
    "        }{\\sigma(c_{\\text{pos}} \\cdot w)}\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &= \n",
    "    -\\left[ w \\left[ 1 - \\sigma(c_{\\text{pos}} \\cdot w) \\right] \\right]\n",
    "    \\\\\n",
    "    &= \n",
    "    w [\\sigma(c_{\\text{pos}} \\cdot w) - 1]\n",
    "    \\\\\n",
    "    \\frac{\\partial}{\\partial c_{\\text{pos}}} \\sigma(c_{\\text{pos}} \\cdot w)\n",
    "    &=\n",
    "    \\frac{\\partial}{\\partial c_{\\text{pos}}} \n",
    "    \\frac{1}{1 + e^{-c_{\\text{pos}} \\cdot w}}\n",
    "    &\n",
    "    \\color{red}{\\text{EQ 2}}\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{\\partial}{\\partial c_{\\text{pos}}} \n",
    "    [1 + e^{-c_{\\text{pos}} \\cdot w}]^{-1}\n",
    "    \\\\\n",
    "    &=\n",
    "    -[1 + e^{-c_{\\text{pos}} \\cdot w}]^{-2}\n",
    "    \\frac{\\partial}{\\partial c_{\\text{pos}}} \n",
    "    [1 + e^{-c_{\\text{pos}} \\cdot w}]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-1}{[1 + e^{-c_{\\text{pos}} \\cdot w}]^{2}}\n",
    "    \\frac{\\partial}{\\partial c_{\\text{pos}}} \n",
    "    [1 + e^{-c_{\\text{pos}} \\cdot w}]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-1}{[1 + e^{-c_{\\text{pos}} \\cdot w}]^{2}}\n",
    "    \\frac{\\partial}{\\partial c_{\\text{pos}}} \n",
    "    e^{-c_{\\text{pos}} \\cdot w}\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-e^{-c_{\\text{pos}} \\cdot w}}{[1 + e^{-c_{\\text{pos}} \\cdot w}]^{2}}\n",
    "    \\frac{\\partial}{\\partial c_{\\text{pos}}} \n",
    "    [-c_{\\text{pos}} \\cdot w]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{we^{-c_{\\text{pos}} \\cdot w}}{[1 + e^{-c_{\\text{pos}} \\cdot w}]^{2}}\n",
    "    \\\\\n",
    "    &=\n",
    "    w\n",
    "    \\left[\\frac{1}{1 + e^{-c_{\\text{pos}} \\cdot w}}\\right]\n",
    "    \\left[\\frac{e^{-c_{\\text{pos}} \\cdot w}}{1 + e^{-c_{\\text{pos}} \\cdot w}}\\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    w\n",
    "    \\sigma(c_{\\text{pos}} \\cdot w)\n",
    "    \\left[ \\frac{e^{-c_{\\text{pos}} \\cdot w}}{1 + e^{-c_{\\text{pos}} \\cdot w}} \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    w\n",
    "    \\sigma(c_{\\text{pos}} \\cdot w)\n",
    "    \\left[ \\frac{1 + e^{-c_{\\text{pos}} \\cdot w} - 1}{1 + e^{-c_{\\text{pos}} \\cdot w}} \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    w\n",
    "    \\sigma(c_{\\text{pos}} \\cdot w)\n",
    "    \\left[\n",
    "        \\frac{1 + e^{-c_{\\text{pos}} \\cdot w}}{1 + e^{-c_{\\text{pos}} \\cdot w}} -\n",
    "        \\frac{1}{1 + e^{-c_{\\text{pos}} \\cdot w}}\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    w \\sigma(c_{\\text{pos}} \\cdot w) \\left[ 1 - \\sigma(c_{\\text{pos}} \\cdot w) \\right]\n",
    "    \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Derivative of loss with respect to $c_{\\text{neg}_i}$ \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\frac{\\partial L_{\\text{CE}}}{\\partial c_{\\text{neg}_i}}\n",
    "    &=\n",
    "    -\\frac{\\partial}{\\partial c_{\\text{neg}_i}}\n",
    "    \\left[\n",
    "        \\log p(+|w, c_{\\text{pos}}) + \n",
    "        \\sum^K_{j=1} \\log p(-|w, c_{\\text{neg}_j})\n",
    "    \\right]\n",
    "    &\n",
    "    \\color{red}{\\text{EQ 1}}\n",
    "    \\\\\n",
    "    &=\n",
    "    -\n",
    "    \\left[\n",
    "        \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \\log p(+|w, c_{\\text{pos}}) + \n",
    "        \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \\sum^K_{j=1} \\log p(-|w, c_{\\text{neg}_j})\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    -\n",
    "    \\left[\n",
    "        \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "        \\sum^K_{j=1} \\log p(-|w, c_{\\text{neg}_j})\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    -\n",
    "    \\left[\n",
    "        \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "        \\sum^K_{j=1} \\log [1 - p(+|w, c_{\\text{neg}_j})]\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    -\n",
    "    \\left[\n",
    "        \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "        \\log [1 - p(+|w, c_{\\text{neg}_i})]\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    - \\left[\n",
    "        \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "        \\log [1 - \\sigma(c_{\\text{neg}_i} \\cdot w)]\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    - \\left[\n",
    "        \\frac{1}{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "        \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "        [1 - \\sigma(c_{\\text{neg}_i} \\cdot w)]\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    - \\left[\n",
    "        \\frac{1}{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "        \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "        -\\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{1}{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "    \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "    \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{1}{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "    [\\color{red}{\\text{EQ 2}}]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{1}{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "    \\left[w \\sigma(c_{\\text{neg}_i} \\cdot w) \\left[ 1 - \\sigma(c_{\\text{neg}_i} \\cdot w) \\right]\\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{\n",
    "        w \\sigma(c_{\\text{neg}_i} \\cdot w) \\left[ 1 - \\sigma(c_{\\text{neg}_i} \\cdot w) \\right]\n",
    "    }{1 - \\sigma(c_{\\text{neg}_i} \\cdot w)}\n",
    "    \\\\\n",
    "    &=\n",
    "    w \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    \\\\\n",
    "    \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    &=\n",
    "    \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "    \\frac{1}{1 + e^{-c_{\\text{neg}_i} \\cdot w}}\n",
    "    &\n",
    "    \\color{red}{\\text{EQ 2}}\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "    [1 + e^{-c_{\\text{neg}_i} \\cdot w}]^{-1}\n",
    "    \\\\\n",
    "    &=\n",
    "    -[1 + e^{-c_{\\text{neg}_i} \\cdot w}]^{-2}\n",
    "    \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "    [1 + e^{-c_{\\text{neg}_i} \\cdot w}]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-1}{[1 + e^{-c_{\\text{neg}_i} \\cdot w}]^{2}}\n",
    "    \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "    [1 + e^{-c_{\\text{neg}_i} \\cdot w}]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-1}{[1 + e^{-c_{\\text{neg}_i} \\cdot w}]^{2}}\n",
    "    \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "    e^{-c_{\\text{neg}_i} \\cdot w}\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{-e^{-c_{\\text{neg}_i} \\cdot w}}{[1 + e^{-c_{\\text{neg}_i} \\cdot w}]^{2}}\n",
    "    \\frac{\\partial}{\\partial c_{\\text{neg}_i}} \n",
    "    [-c_{\\text{neg}_i} \\cdot w]\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{we^{-c_{\\text{neg}_i} \\cdot w}}{[1 + e^{-c_{\\text{neg}_i} \\cdot w}]^{2}}\n",
    "    \\\\\n",
    "    &=\n",
    "    w\n",
    "    \\left[\\frac{1}{1 + e^{-c_{\\text{neg}_i} \\cdot w}}\\right]\n",
    "    \\left[\\frac{e^{-c_{\\text{neg}_i} \\cdot w}}{1 + e^{-c_{\\text{neg}_i} \\cdot w}}\\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    w\n",
    "    \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    \\left[ \\frac{e^{-c_{\\text{neg}_i} \\cdot w}}{1 + e^{-c_{\\text{neg}_i} \\cdot w}} \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    w\n",
    "    \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    \\left[ \\frac{1 + e^{-c_{\\text{neg}_i} \\cdot w} - 1}{1 + e^{-c_{\\text{neg}_i} \\cdot w}} \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    w\n",
    "    \\sigma(c_{\\text{neg}_i} \\cdot w)\n",
    "    \\left[\n",
    "        \\frac{1 + e^{-c_{\\text{neg}_i} \\cdot w}}{1 + e^{-c_{\\text{neg}_i} \\cdot w}} -\n",
    "        \\frac{1}{1 + e^{-c_{\\text{neg}_i} \\cdot w}}\n",
    "    \\right]\n",
    "    \\\\\n",
    "    &=\n",
    "    w \\sigma(c_{\\text{neg}_i} \\cdot w) \\left[ 1 - \\sigma(c_{\\text{neg}_i} \\cdot w) \\right]\n",
    "    \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-people",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- Jurafsky, Daniel, and James H. Martin. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition. Pearson, 2020."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
